{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Configure the Groq client\n",
    "from groq import Groq\n",
    "\n",
    "# Set your Groq API key\n",
    "api_key = \"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\"  # Replace with your actual API key\n",
    "if not api_key:\n",
    "    raise ValueError(\"Please set your Groq API key in the 'api_key' variable.\")\n",
    "\n",
    "client = Groq(api_key=api_key)\n",
    "\n",
    "# File to read and write\n",
    "input_file_path = \"/content/trials - Copy.csv\"  # Input file path\n",
    "output_file_path = \"refined.csv\"  # Output file path\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(input_file_path, low_memory=False)\n",
    "\n",
    "# Remove unintended empty rows\n",
    "df = df.dropna(how=\"all\").reset_index(drop=True)\n",
    "\n",
    "# Define columns to clean\n",
    "columns_to_clean = [\"Study Title\", \"Primary Outcome Measures\", \"Secondary Outcome Measures\", \"criteria\"]\n",
    "\n",
    "# Merge all columns into a single column for processing\n",
    "def merge_columns(row):\n",
    "    return \" \\n\".join([str(row[col]) for col in columns_to_clean if col in row and not pd.isnull(row[col])])\n",
    "\n",
    "df[\"Merged_Content\"] = df.apply(merge_columns, axis=1)\n",
    "\n",
    "# Function to clean and extract relationships using Groq\n",
    "def extract_relationships(content, row_index):\n",
    "    if pd.isnull(content):\n",
    "        return [None, None, None, None, None]\n",
    "\n",
    "    # Truncate content if it exceeds a certain limit to avoid API errors\n",
    "    max_length = 2000  # Adjust the limit as needed\n",
    "    if len(content) > max_length:\n",
    "        content = content[:max_length] + \"...\"\n",
    "\n",
    "    \n",
    "\n",
    "    prompt = (\n",
    "          \"The following text is a merged representation of a clinical trials dataset row. \"\n",
    "          \"Extract only valid and concise relationships from it in the exact format below:\\n\"\n",
    "          \"'Subject', 'Relationship', 'Object' (one per line):\\n\\n\"\n",
    "          \"'involves (Disease)': 'The name of the primary disease or condition being studied \"\n",
    "          '(e.g., \"Diabetes\", \"Hypertension\").\\'\\n\\n'\n",
    "          \"'evaluates (Drug)': 'The name of the drug, therapy, or intervention being evaluated. \"\n",
    "          '(e.g., \"Aspirin\", \"Gene Therapy\"). \\'\\n\\n'\n",
    "          \"'measures_primary (Primary Outcome)': 'The main outcome or result the trial is designed \"\n",
    "          'to measure, in up to 5 words (e.g., \"Reduction in blood pressure\").\\'\\n\\n'\n",
    "          \"'measures_secondary (Secondary Outcome)': 'Additional outcomes or results measured in the trial, \"\n",
    "          'in up to 5 words (e.g., \"Improved insulin sensitivity\").\\'\\n\\n'\n",
    "          \"'has_criteria (Criteria)': 'Key eligibility criteria for participants in up to 5 words \"\n",
    "          '(e.g., \"Ages 18-65, no diabetes\").\\'\\n\\n'\n",
    "          \"Rules:\\n\\n\"\n",
    "          \"- 'Assume you are a biomedical expert with a deep understanding of clinical trial terminology.'\\n\"\n",
    "          # \"- 'If the information for an object cannot be found or is ambiguous, write \\\"None\\\" instead of guessing.'\\n\"\n",
    "          \"- 'Objects must be relevant, concise, and meaningful, with a maximum of 5 words. Avoid long phrases, generic terms, or irrelevant outputs.'\\n\\n\"\n",
    "          \"'Content to analyze\\n'\"\n",
    "          f\"\\n{content}\"\n",
    ")\n",
    "\n",
    "    # Call the Groq API to get a response\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gemma2-9b-it\",  # Use the appropriate model\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=1,\n",
    "        max_tokens=1024,\n",
    "        top_p=1,\n",
    "        stream=False,\n",
    "        stop=None,\n",
    "    )\n",
    "\n",
    "    # Extract the response text from the correct object\n",
    "    response = completion.choices[0].message.content\n",
    "\n",
    "    # Parse the response text to extract the relationships\n",
    "    extracted = [None, None, None, None, None]\n",
    "    for line in response.splitlines():\n",
    "        if \"involves\" in line:\n",
    "            extracted[0] = line.split(\",\", 2)[-1].strip()\n",
    "        elif \"evaluates\" in line:\n",
    "            extracted[1] = line.split(\",\", 2)[-1].strip()\n",
    "        elif \"measures_primary\" in line:\n",
    "            extracted[2] = line.split(\",\", 2)[-1].strip()\n",
    "        elif \"measures_secondary\" in line:\n",
    "            extracted[3] = line.split(\",\", 2)[-1].strip()\n",
    "        elif \"has_criteria\" in line:\n",
    "            extracted[4] = line.split(\",\", 2)[-1].strip()\n",
    "\n",
    "    print(f\"Row {row_index} processed.\")  # Log row completion\n",
    "    return extracted\n",
    "\n",
    "# Ensure output file is cleared or created\n",
    "with open(output_file_path, 'w') as f:\n",
    "    f.write(\"Subject,Relationship,Object\\n\")\n",
    "\n",
    "# Process each row, extract relationships, and write to the CSV immediately\n",
    "for index, row in df.iloc[0:].iterrows():\n",
    "    extracted = extract_relationships(row[\"Merged_Content\"], index)\n",
    "    subject = row.get(\"NCT Number\", f\"Row {index}\")  # Replace \"Study ID\" with appropriate column name for Subject\n",
    "\n",
    "    # Write each relationship as a separate row in the output file\n",
    "    with open(output_file_path, 'a') as f:\n",
    "        f.write(f\"{subject},involves,{extracted[0]}\\n\")\n",
    "        f.write(f\"{subject},evaluates,{extracted[1]}\\n\")\n",
    "        f.write(f\"{subject},measures_primary,{extracted[2]}\\n\")\n",
    "        f.write(f\"{subject},measures_secondary,{extracted[3]}\\n\")\n",
    "        f.write(f\"{subject},has_criteria,{extracted[4]}\\n\")\n",
    "\n",
    "    print(f\"Row {index} written to file.\")\n",
    "\n",
    "print(f\"Data extraction complete. Updated data saved to: {output_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
